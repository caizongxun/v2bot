{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration - BTC 15m\n",
    "\n",
    "First notebook to test and explore cryptocurrency OHLCV data.\n",
    "\n",
    "## Steps:\n",
    "1. Load data from HuggingFace\n",
    "2. Clean and validate\n",
    "3. Basic statistics\n",
    "4. Visualize OHLC patterns\n",
    "5. Test windowing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q huggingface-hub pandas numpy matplotlib seaborn scikit-learn\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add repo to path\n",
    "if 'v2bot' not in sys.path:\n",
    "    sys.path.insert(0, '/root/v2bot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print('[Setup] All imports successful')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Data from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Download BTC 15m data\n",
    "repo_id = 'zongowo111/v2-crypto-ohlcv-data'\n",
    "symbol = 'BTC'\n",
    "interval = '15m'\n",
    "\n",
    "print(f'[Step 1] Downloading {symbol}_{interval} from {repo_id}...')\n",
    "\n",
    "file_path = hf_hub_download(\n",
    "    repo_id=repo_id,\n",
    "    filename=f'klines/{symbol}/{symbol}_{interval}.csv',\n",
    "    repo_type='dataset'\n",
    ")\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "print(f'[Step 1] SUCCESS: Loaded {len(df)} rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Explore Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*70)\n",
    "print('RAW DATA EXPLORATION')\n",
    "print('='*70)\n",
    "\n",
    "print(f'\\nShape: {df.shape}')\n",
    "print(f'\\nColumns: {df.columns.tolist()}')\n",
    "print(f'\\nData types:\\n{df.dtypes}')\n",
    "print(f'\\nMissing values:\\n{df.isnull().sum()}')\n",
    "\n",
    "print(f'\\nFirst 5 rows:')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Convert timestamp\n",
    "if 'timestamp' in df_clean.columns:\n",
    "    df_clean['timestamp'] = pd.to_datetime(df_clean['timestamp'])\n",
    "    df_clean = df_clean.sort_values('timestamp')\n",
    "\n",
    "# Remove duplicates\n",
    "initial_len = len(df_clean)\n",
    "df_clean = df_clean.drop_duplicates(subset=['timestamp'] if 'timestamp' in df_clean.columns else None)\n",
    "print(f'[Cleaning] Removed {initial_len - len(df_clean)} duplicate rows')\n",
    "\n",
    "# Remove missing values\n",
    "initial_len = len(df_clean)\n",
    "df_clean = df_clean.dropna(subset=['open', 'high', 'low', 'close', 'volume'])\n",
    "print(f'[Cleaning] Removed {initial_len - len(df_clean)} rows with missing OHLCV')\n",
    "\n",
    "# Ensure all values are positive\n",
    "numeric_cols = ['open', 'high', 'low', 'close', 'volume']\n",
    "initial_len = len(df_clean)\n",
    "df_clean = df_clean[df_clean[numeric_cols].gt(0).all(axis=1)]\n",
    "print(f'[Cleaning] Removed {initial_len - len(df_clean)} rows with zero/negative values')\n",
    "\n",
    "# Reset index\n",
    "df_clean = df_clean.reset_index(drop=True)\n",
    "\n",
    "print(f'\\n[Cleaning] Final shape: {df_clean.shape}')\n",
    "if 'timestamp' in df_clean.columns:\n",
    "    print(f'[Cleaning] Date range: {df_clean[\"timestamp\"].min()} to {df_clean[\"timestamp\"].max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*70)\n",
    "print('STATISTICS')\n",
    "print('='*70 + '\\n')\n",
    "\n",
    "numeric_cols = ['open', 'high', 'low', 'close', 'volume']\n",
    "print(df_clean[numeric_cols].describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot OHLC\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Price trend\n",
    "axes[0].plot(df_clean['close'], linewidth=0.8, label='Close')\n",
    "axes[0].fill_between(range(len(df_clean)), df_clean['low'], df_clean['high'], alpha=0.2)\n",
    "axes[0].set_title(f'{symbol}_{interval} - Price Trend')\n",
    "axes[0].set_ylabel('Price (USD)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Volume\n",
    "axes[1].bar(range(len(df_clean)), df_clean['volume'], width=1.0, alpha=0.6)\n",
    "axes[1].set_title(f'{symbol}_{interval} - Volume')\n",
    "axes[1].set_xlabel('Time (15min candles)')\n",
    "axes[1].set_ylabel('Volume')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'[Visualization] Chart displayed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Returns Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate returns\n",
    "df_clean['returns'] = df_clean['close'].pct_change() * 100  # in percentage\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Distribution\n",
    "axes[0].hist(df_clean['returns'].dropna(), bins=100, alpha=0.7, edgecolor='black')\n",
    "axes[0].set_title('Returns Distribution')\n",
    "axes[0].set_xlabel('Returns (%)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].axvline(df_clean['returns'].mean(), color='r', linestyle='--', label=f'Mean: {df_clean[\"returns\"].mean():.4f}%')\n",
    "axes[0].legend()\n",
    "\n",
    "# Time series\n",
    "axes[1].plot(df_clean['returns'], linewidth=0.5, alpha=0.7)\n",
    "axes[1].set_title('Returns Over Time')\n",
    "axes[1].set_xlabel('Time')\n",
    "axes[1].set_ylabel('Returns (%)')\n",
    "axes[1].axhline(0, color='k', linestyle='-', linewidth=0.3)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'[Returns] Mean: {df_clean[\"returns\"].mean():.6f}%')\n",
    "print(f'[Returns] Std: {df_clean[\"returns\"].std():.6f}%')\n",
    "print(f'[Returns] Min: {df_clean[\"returns\"].min():.6f}%')\n",
    "print(f'[Returns] Max: {df_clean[\"returns\"].max():.6f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Test Data Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create windows\n",
    "window_size = 100  # 100 * 15min = 1500min = 25 hours\n",
    "\n",
    "numeric_cols = ['open', 'high', 'low', 'close', 'volume']\n",
    "data_matrix = df_clean[numeric_cols].values\n",
    "\n",
    "windows = []\n",
    "for i in range(0, len(data_matrix) - window_size + 1, 1):\n",
    "    window = data_matrix[i:i+window_size]\n",
    "    windows.append(window)\n",
    "\n",
    "print(f'[Windowing] Created {len(windows)} windows')\n",
    "print(f'[Windowing] Window size: {window_size} (shape: {windows[0].shape})')\n",
    "print(f'[Windowing] Total features per window: {window_size * 5} (100 candles * 5 OHLCV)')\n",
    "\n",
    "# Show sample window\n",
    "print(f'\\n[Sample] First window (first 5 candles):')\n",
    "print(pd.DataFrame(windows[0][:5], columns=['Open', 'High', 'Low', 'Close', 'Volume']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Train/Val/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based split\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "n = len(df_clean)\n",
    "train_end = int(n * train_ratio)\n",
    "val_end = train_end + int(n * val_ratio)\n",
    "\n",
    "train_df = df_clean[:train_end]\n",
    "val_df = df_clean[train_end:val_end]\n",
    "test_df = df_clean[val_end:]\n",
    "\n",
    "print(f'[Split] Total: {len(df_clean)} rows')\n",
    "print(f'[Split] Train: {len(train_df)} ({train_ratio*100:.1f}%)')\n",
    "print(f'[Split] Val:   {len(val_df)} ({val_ratio*100:.1f}%)')\n",
    "print(f'[Split] Test:  {len(test_df)} ({test_ratio*100:.1f}%)')\n",
    "\n",
    "if 'timestamp' in df_clean.columns:\n",
    "    print(f'\\n[Train] {train_df[\"timestamp\"].min()} to {train_df[\"timestamp\"].max()}')\n",
    "    print(f'[Val]   {val_df[\"timestamp\"].min()} to {val_df[\"timestamp\"].max()}')\n",
    "    print(f'[Test]  {test_df[\"timestamp\"].min()} to {test_df[\"timestamp\"].max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*70)\n",
    "print('DATA EXPLORATION COMPLETE')\n",
    "print('='*70)\n",
    "\n",
    "summary = {\n",
    "    'Dataset': f'{symbol}_{interval}',\n",
    "    'Total Rows': len(df_clean),\n",
    "    'Features': 'OHLCV',\n",
    "    'Window Size': window_size,\n",
    "    'Total Windows': len(windows),\n",
    "    'Train Rows': len(train_df),\n",
    "    'Val Rows': len(val_df),\n",
    "    'Test Rows': len(test_df),\n",
    "    'Avg Return': f\"{df_clean['returns'].mean():.6f}%\",\n",
    "    'Return Std': f\"{df_clean['returns'].std():.6f}%\",\n",
    "}\n",
    "\n",
    "for key, val in summary.items():\n",
    "    print(f'{key:.<30} {val}')\n",
    "\n",
    "print('='*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
